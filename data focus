import os
import re
import asyncio
import requests
import pandas as pd
from io import BytesIO
from datetime import datetime, timedelta, timezone
from pathlib import Path
from openpyxl import Workbook
from playwright.async_api import async_playwright

# =========================
# CONFIG
# =========================
URL_LANDING = "https://www3.bcb.gov.br/expectativas2/"
URL_XLS = "https://www3.bcb.gov.br/expectativas2/rest/publico/downloadSeriesEstatisticasXls"

WINDOW_DAYS = 30
MAX_ATTEMPTS = 20
TIMEOUT = 60

OUT_FILE = Path("focus_ipca_selic_2026_2027.xlsx")

COMMON = {
    "periodo": "ANUAL",
    "consultaIndicadoresDescontinuados": False,
    "tipoEstatistica": "MEDIANA",
    "baseCalculoEstatistica": "TRINTA_DIAS",
    "__ocultarFiltro__": True,
    "__mostraResultadoSeriesEstatisticas__": True,
}

SERIES = [
    {
        "sheet": "IPCA",
        "title_hint": "IPCA",
        "payload": {
            **COMMON,
            "grupoIndicador": "INDICE_PRECOS_GRUPO",
            "codigosIndicadores": ["IPCA"],
        },
    },
    {
        "sheet": "SELIC",
        "title_hint": "SELIC",
        "payload": {
            **COMMON,
            "grupoIndicador": "TAXAS_GRUPO",
            "codigosIndicadores": ["META_TAXA_SELIC"],
        },
    },
]


# =========================
# HELPERS
# =========================
def iso_z(dt: datetime) -> str:
    return dt.astimezone(timezone.utc).isoformat(timespec="milliseconds").replace("+00:00", "Z")

def looks_like_excel_bytes(b: bytes, content_type: str) -> bool:
    if not b or len(b) < 1000:
        return False
    if b[:2] in (b"PK", b"\xD0\xCF"):  # xlsx/xls
        return True
    ct = (content_type or "").lower()
    if "ms-excel" in ct or "spreadsheet" in ct or "application/vnd" in ct:
        return True
    return len(b) > 10_000

def find_edge_path() -> str:
    candidates = [
        r"C:\Program Files (x86)\Microsoft\Edge\Application\msedge.exe",
        r"C:\Program Files\Microsoft\Edge\Application\msedge.exe",
    ]
    for pth in candidates:
        if os.path.exists(pth):
            return pth
    from shutil import which
    pth = which("msedge")
    if pth:
        return pth
    raise RuntimeError(
        "Não encontrei o Microsoft Edge.\n"
        "Procurei em:\n" + "\n".join(candidates) +
        "\n\nSe o Edge estiver em outro caminho, ajuste find_edge_path()."
    )

def parse_and_filter_from_bytes(xls_bytes: bytes, title_hint: str) -> tuple[str, pd.DataFrame]:
    raw = pd.read_excel(BytesIO(xls_bytes), header=None).dropna(how="all")

    # título (linha A1)
    title = None
    for i in range(min(10, len(raw))):
        v = raw.iloc[i, 0]
        if isinstance(v, str):
            up = v.upper()
            if title_hint.upper() in up or "MEDIANA" in up or "PERÍODO" in up or "PERIODO" in up:
                title = v.strip()
                break
    title = title or title_hint

    # acha header Data/2026/2027
    header_idx = None
    for i in range(min(150, len(raw))):
        row = raw.iloc[i].astype(str)
        has_data = row.str.contains(r"\bData\b", regex=True).any()
        has_26 = row.str.contains(r"\b2026\b", regex=True).any()
        has_27 = row.str.contains(r"\b2027\b", regex=True).any()
        if has_data and has_26 and has_27:
            header_idx = i
            break

    if header_idx is None:
        raw.head(80).to_excel(f"debug_preview_{title_hint}.xlsx", index=False, header=False)
        raise RuntimeError(f"[{title_hint}] Não achei header Data/2026/2027 (salvei debug_preview_{title_hint}.xlsx).")

    header = raw.iloc[header_idx].tolist()

    def norm(h):
        s = str(h).strip()
        if re.search(r"\bData\b", s): return "Data"
        if re.search(r"\b2026\b", s): return "2026"
        if re.search(r"\b2027\b", s): return "2027"
        m = re.search(r"\b(20\d{2})\b", s)
        return m.group(1) if m else s

    header = [norm(x) if x is not None else "" for x in header]

    df = raw.iloc[header_idx + 1 :].copy()
    df.columns = header

    if "Data" not in df.columns or "2026" not in df.columns or "2027" not in df.columns:
        df.head(80).to_excel(f"debug_df_{title_hint}.xlsx", index=False)
        raise RuntimeError(f"[{title_hint}] Não consegui mapear Data/2026/2027 (salvei debug_df_{title_hint}.xlsx).")

    # mantém só Data/2026/2027
    df = df[["Data", "2026", "2027"]].copy()

    # converte Data para date (SEM HORA)
    df["Data"] = pd.to_datetime(df["Data"], dayfirst=True, errors="coerce").dt.date

    # filtra e ordena
    df = df[df["Data"].notna()].sort_values("Data")

    return title, df

def write_sheet(wb: Workbook, sheet_name: str, title: str, df: pd.DataFrame):
    # remove aba se existir
    if sheet_name in wb.sheetnames:
        wb.remove(wb[sheet_name])

    ws = wb.create_sheet(sheet_name)

    # Linha de título
    ws["A1"] = title

    # Header
    ws.append(["Data", "2026", "2027"])

    # Dados (blindagem TOTAL: se vier datetime, corta .date())
    for _, r in df.iterrows():
        d = r["Data"]
        if hasattr(d, "date"):  # caso seja datetime.datetime
            d = d.date()
        ws.append([d, r["2026"], r["2027"]])

    # Força formato visual dd/mm/yyyy na coluna A (dados começam na linha 3)
    for cell in ws["A"][3:]:
        cell.number_format = "DD/MM/YYYY"


# =========================
# TOKENS VIA EDGE (Playwright)
# =========================
async def get_tokens_via_playwright_edge(headless: bool = True):
    edge_path = find_edge_path()

    async with async_playwright() as p:
        browser = await p.chromium.launch(
            headless=headless,
            executable_path=edge_path,
            args=["--disable-gpu"]
        )
        context = await browser.new_context()
        page = await context.new_page()
        await page.goto(URL_LANDING, wait_until="domcontentloaded")

        # tenta aceitar cookies se aparecer
        for sel in [
            "text=Aceitar", "text=Aceito", "text=Concordo",
            "button:has-text('Aceitar')", "button:has-text('Concordo')",
            "button:has-text('OK')"
        ]:
            try:
                await page.click(sel, timeout=1200)
                break
            except Exception:
                pass

        await page.wait_for_timeout(800)

        cookies = await context.cookies()
        cookie_dict = {c["name"]: c["value"] for c in cookies}
        xsrf = cookie_dict.get("XSRF-TOKEN")
        ua = await page.evaluate("() => navigator.userAgent")

        await browser.close()

        if not xsrf:
            raise RuntimeError("Não encontrei XSRF-TOKEN nos cookies.")
        return cookie_dict, xsrf, ua


# =========================
# DOWNLOAD XLS
# =========================
def download_xls_bytes(cookie_dict: dict, xsrf: str, ua: str, payload_base: dict) -> bytes:
    s = requests.Session()
    s.cookies.update(cookie_dict)

    headers = {
        "accept": "application/json, text/plain, */*",
        "content-type": "application/json",
        "origin": "https://www3.bcb.gov.br",
        "referer": "https://www3.bcb.gov.br/expectativas2/",
        "user-agent": ua,
        "x-xsrf-token": xsrf,
    }

    end = datetime.now(timezone.utc)
    code = payload_base.get("codigosIndicadores", ["?"])[0]

    for i in range(MAX_ATTEMPTS):
        payload = dict(payload_base)
        payload["dataFim"] = iso_z(end)
        payload["dataInicio"] = iso_z(end - timedelta(days=WINDOW_DAYS))

        print(f"[{code}] Tentando dataFim={payload['dataFim']} (tentativa {i+1}/{MAX_ATTEMPTS})")
        r = s.post(URL_XLS, headers=headers, json=payload, timeout=TIMEOUT)

        ct = r.headers.get("Content-Type", "")
        if r.status_code == 200 and looks_like_excel_bytes(r.content, ct):
            return r.content

        end -= timedelta(days=1)

    raise RuntimeError(f"Não consegui baixar XLS (bytes) para {code}.")


# =========================
# MAIN
# =========================
async def main():
    cookie_dict, xsrf, ua = await get_tokens_via_playwright_edge(headless=True)

    wb = Workbook()
    if "Sheet" in wb.sheetnames:
        wb.remove(wb["Sheet"])

    for s in SERIES:
        xls_bytes = download_xls_bytes(cookie_dict, xsrf, ua, s["payload"])
        title, df = parse_and_filter_from_bytes(xls_bytes, title_hint=s["title_hint"])
        write_sheet(wb, s["sheet"], title, df)
        print(f"[OK] Aba pronta: {s['sheet']}")

    wb.save(OUT_FILE)
    print(f"[OK] Arquivo gerado: {OUT_FILE}")


if __name__ == "__main__":
    asyncio.run(main())
